{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/5dtHh4NzjVsDuyBpTq/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ifeanyi55/Gemma-Agents/blob/main/Synthetic_Data_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install required libraries\n",
        "!pip install -q transformers torch\n",
        "!pip install sdv"
      ],
      "metadata": {
        "id": "eqptPuVcPsRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# login into Hugging Face Hub with your HF token\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "isAPlOOnQMLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download function gemma model\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "\n",
        "GEMMA_MODEL_ID = \"google/functiongemma-270m-it\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(GEMMA_MODEL_ID, device_map=\"auto\")\n",
        "model = AutoModelForCausalLM.from_pretrained(GEMMA_MODEL_ID, dtype=\"auto\", device_map=\"auto\")"
      ],
      "metadata": {
        "id": "IcNiZYeFQV11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can generate synthetic data of the following kinds: companies, persons, addresses, places, users, credit cards, books, and text. These are the categories that the [Faker API](https://fakerapi.it/) in the custom function permits."
      ],
      "metadata": {
        "id": "lMBRzKj9olX1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUf3qmGhPplP"
      },
      "outputs": [],
      "source": [
        "# build agent for generating synthetic data\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "\n",
        "# define function schema\n",
        "synthetic_data_function_schema = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"synthetic_data_generator\",\n",
        "        \"description\": \"Generates synthetic data points.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"category\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The category of data to generate, e.g. persons\",\n",
        "                },\n",
        "                \"quantity\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The quantity of data points to generate, e.g. 1000\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"category\",\"quantity\"],\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "# build the function\n",
        "def synthetic_data_generator(category:str,quantity:int) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  A function for generating synthetic data points\n",
        "  Args:\n",
        "      category: The category of data to generate\n",
        "      quantity: The number of data points to generate\n",
        "  Returns:\n",
        "          A dataframe of synthetic data points.\n",
        "  \"\"\"\n",
        "  # call Faker API\n",
        "  url = f\"https://fakerapi.it/api/v2/{category}?_quantity=200\"\n",
        "\n",
        "  resp = requests.get(url)\n",
        "\n",
        "  df = pd.DataFrame(resp.json()[\"data\"])\n",
        "\n",
        "  # drop 'address' or 'addresses' column from the dataframe\n",
        "  if \"address\" in df.columns:\n",
        "    df = df.drop(columns=[\"address\"])\n",
        "  elif \"addresses\" in df.columns:\n",
        "    df = df.drop(columns=[\"addresses\"])\n",
        "  else:\n",
        "    metadata = SingleTableMetadata()\n",
        "\n",
        "    # extract metatdata from the table\n",
        "    metadata.detect_from_dataframe(df)\n",
        "\n",
        "    synthesizer = GaussianCopulaSynthesizer(metadata)\n",
        "\n",
        "    # train ML model for generating synthetic data\n",
        "    synthesizer.fit(data=df)\n",
        "\n",
        "    # generate synthetic data\n",
        "    synthetic_data = synthesizer.sample(num_rows=quantity)\n",
        "\n",
        "    return synthetic_data\n",
        "\n",
        "# add function to a registry of tools\n",
        "tools = {\n",
        "    \"synthetic_data_generator\":synthetic_data_generator\n",
        "}\n",
        "\n",
        "# model's turn\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"developer\",\n",
        "        # it is important to include this system prompt to enable the model to call tools.\n",
        "        \"content\": \"You are a model that can do function calling with the following functions\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Can you generate 8000 synthetic data points of different addresses?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(message, tools = [synthetic_data_function_schema],add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
        "\n",
        "out = model.generate(**inputs.to(model.device), pad_token_id=processor.eos_token_id, max_new_tokens=128)\n",
        "output = processor.decode(out[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n",
        "\n",
        "# developer's turn\n",
        "def extract_tool_calls(text):\n",
        "    def cast(v):\n",
        "        try: return int(v)\n",
        "        except:\n",
        "            try: return float(v)\n",
        "            except: return {'true': True, 'false': False}.get(v.lower(), v.strip(\"'\\\"\"))\n",
        "\n",
        "    return [{\n",
        "        \"name\": name,\n",
        "        \"arguments\": {\n",
        "            k: cast((v1 or v2).strip())\n",
        "            for k, v1, v2 in re.findall(r\"(\\w+):(?:<escape>(.*?)<escape>|([^,}]*))\", args)\n",
        "        }\n",
        "    } for name, args in re.findall(r\"<start_function_call>call:(\\w+)\\{(.*?)\\}<end_function_call>\", text, re.DOTALL)]\n",
        "\n",
        "# extract the tool call output\n",
        "calls = extract_tool_calls(output)\n",
        "\n",
        "if calls:\n",
        "    message.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"tool_calls\": [{\"type\": \"function\", \"function\": call} for call in calls]\n",
        "    })\n",
        "    print(message[-1])\n",
        "\n",
        "    # call the function and get the result\n",
        "    results = [\n",
        "        {\"name\": c['name'], \"response\": tools[c['name']](**c['arguments'])}\n",
        "        for c in calls\n",
        "    ]\n",
        "\n",
        "print(results[0][\"response\"])\n"
      ]
    }
  ]
}